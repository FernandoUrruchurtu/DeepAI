{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este curso, se enseñará como funciona cada uno de los aspectos necesarios para realizar un ciclo correcto de investigación y experimentación con redes neuronales.\n",
    "\n",
    "Cuando queremos realizar o aplicar proyectos de ML, es necesario escoger varios parámetros:\n",
    "\n",
    "- Número de capas\n",
    "\n",
    "- Número de unidades ocultas\n",
    "\n",
    "- Tasa de aprendizaje\n",
    "\n",
    "- Funciones de activación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependiendo de cada aplicación que se tenga, tenemos una idea, la codificamos y experimentamos con ella. \n",
    "\n",
    "Aquí es dónde jugamos con distintas variables dependiendo del resultado que tengamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo seleccionar correctamente el Train/dev/test sets\n",
    "\n",
    "En la literatura, el dev set es llamado Hold Out Cross Validation set este es útil para evaluar varios modelos y su performance.\n",
    "\n",
    "Antes en el ML se usaba un regla de dedo o rule of thumb de usar el 70/30% pero en la era de Big Data, dónde se tiene muchísima información entonces normalmente se usan porcentajes pequeños por que al final la meta es poder evaluar el performance de nuestro modelo.\n",
    "\n",
    "Algunos ejemplos es usar 98%/1%/1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mismatched train/test distribution.\n",
    "\n",
    "Cuando nuestros datos provienen de diferentes fuentes con varias reglas o situaciones que no tienen la misma distribución de los datios, tenemos que asegurarnos que:\n",
    "\n",
    "- El dev y el test set vienen de la misma distribución.\n",
    "\n",
    "- A veces está bien no tener un test set. Sólo con un dev set estaría bien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias y Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender el bias y el variance, tenemos que mirar dos tipos de métricas claves:\n",
    "\n",
    "- Train set error\n",
    "\n",
    "- Dev set error\n",
    "\n",
    "Entonces, primer ejemplo:\n",
    "\n",
    "#### Overfitting:\n",
    "\n",
    "Tenemos un error muy bajo en el training set y un error relativamente alto en el dev set. Esto significa que nuestro modelo se ajusta demasiado a los datos y no generaliza patrones. En este caso tenemos un high variance\n",
    "\n",
    "#### Underfitting:\n",
    "\n",
    "Tenemos un error muy similar tanto en el train set como en el dev set. Pero bastante alto tanto en train como en dev sets. En este caso, tenemos un high bias.\n",
    "\n",
    "<img src = HT_1.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Recipe for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las primeras preguntas que debemos hacernos son las siguientes:\n",
    "\n",
    "1. Tiene nuestro modelo un alto bias? (Training data performance)\n",
    "\n",
    "En este caso, usamos una red más grande, con más capas o intentar un algoritmo más grande para entrenamiento. \n",
    "\n",
    "Podemos usar diferentes arquitecturas de redes neuronales.\n",
    "\n",
    "2. Tiene nuestro modelo una alta variance?\n",
    "\n",
    "En estecaso, podemos intentar con más datos, regularización o una arquitectura diferente.\n",
    "\n",
    "Ahora bien, desde que implementamos alguna técnica, la otra puede verse afectada. La idea es implementar técnicas que no dañen tanto el bias pero que mejoren el variance. En otros casos, es mejor que se mejore el variance, pero no se dañe mucho el bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una fórmula importante:\n",
    "\n",
    "- $||w^{[l]}||^{2} = \\sum^{n^{[l]}}_{i=1} \\sum^{n^{[l-1]}}_{j=1}(w_{i,j}^{[l]})^{2}$\n",
    "\n",
    "De esta fórmula, es importante saber que el límite para la sumatoria de las i, es debe ser desde 1 hasta $n^{[l]}$ y de j desde 1 hasta $n^{[l-1]}$\n",
    "\n",
    "Las filas i de la matriz, deben ser el número de neuronas, en la capa $n^{[l-1]}$.\n",
    "\n",
    "En cambio, las columnas j de la matriz de los weights, deben ser igual al número de neuronas de la capa anterior $n^{[l]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, repasemos la regularización usando el ejemplo de regresión logística:\n",
    "\n",
    "- Recordemos que queremos minimizar la función de costo J: $min J(w,b)$\n",
    "\n",
    "Dónde J(w,b) = $\\frac{1}{m}\\sum^{m}_{i=1}L(\\hat{y}^{i},y^{i})$\n",
    "\n",
    "- En este caso, lo que hacemos es sumarle a la fórmula anterior: $\\frac{\\lambda}{2m}||w||^{2}$\n",
    "\n",
    "#### Regularización L2\n",
    "\n",
    "- Dónde, $||w||^{2}_{2} = \\sum^{n_x}_{j}w^{2}_{j}$\n",
    "\n",
    "Esta es llamada regularización L2, normalmente se omite la del bias que sería lo mismo. Sin embargo, w es mucho más dimensional que b, donde W tiene muchos más parámetros al ser un vector, pero b es sólo un número escalar. \n",
    "\n",
    "#### Regularización L1\n",
    "\n",
    "Por otro lado, está regularizar los mismos parámetros w, lo que traerá ventajas como que nuestros parámetros w serán más esparcidos, es decir, tendrán bastantes ceros lo que ayuda a tener que usar menos memoria para almacenar los parámetros del modelo.\n",
    "\n",
    "La fórmula de L1 sería la siguiente:\n",
    "\n",
    "- $\\frac{\\lambda}{2m}||w||$\n",
    "\n",
    "- $\\lambda$ es el parámetro de regularización. Es un hiperparámetro que podemos tunear también. En vez de lambda en python, estaremos usando la palabra lambd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, en una red neuronal, dónde tenemos distintas capas, al usar regularización, vamos a tener la siguiente fórmula:\n",
    "\n",
    "- $J(w^{[1]}, b^{[1]}, ... , w^{[l]}, b^{[l]}) = \\frac{1}{m}\\sum^{m}_{i=1}L(\\hat{y}^{i},y^{i}) + \\frac{\\lambda}{2m}\\sum^{L}_{l-1}||w^{[l]}||^{2}$\n",
    "\n",
    "- Dónde: $||w^{[l]}||^{2} = \\sum^{n^{[l]}}_{i=1} \\sum^{n^{[l-1]}}_{j=1}(w_{i,j}^{[l]})^{2}$\n",
    "\n",
    "Este cálculo de la determinante, es llamado la fórma de Frobenius\n",
    "\n",
    "Recordemos que nuestra matriz de W va a ser de tamaño $(n^{[l]}, n^{[l-1]})$\n",
    "\n",
    "Ahora bien, ¿Como implementamos descenso del gradiente?\n",
    "\n",
    "En este caso, lo que procederemos a hacer es en vez de calcularlo de la forma tradicional, en este caso, le sumamos el siguiente término al dw:\n",
    "\n",
    "- $\\frac{\\lambda}{m}w^{[l]}$\n",
    "\n",
    "Al sumarle un término adicional y recordando que nuestro parámetro de actualización es el siguiente:\n",
    "\n",
    "- $w^{[l]} := w^{[l]}-\\alpha dw^{[l]}$\n",
    "\n",
    "Estamos aumentando nuestro valor de dw, lo que en la literatura se conoce como weight decay. Lo que en pocas palabras penaliza aún más nuestros pesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos de optimización para entrenar más rápido las redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actualmente hemos aprendido que la vectorización nos ayuda a realizar cálculos eficientemente en m examples.\n",
    "\n",
    "Dónde, nuestra matriz de X no es más que una de tamaño $(n_x, m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero, ¿qué pasaría si nuestro dataset es bastante grande?. En este caso, sería bastante lento nuestro descenso del gradiente, en estos casos, lo mejor es usar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, lo que se quiere lograr o hacer, es tratar de tomar al menos 1000 ejemplos para entrenar con pequeños lotes de datos que puedan darnos una aproximación de cómo puede ir nuestro módelo.\n",
    "\n",
    "En este caso, podemos ir utilizando 1000 ejemplos e irlos partiendo a través de cada uno de nuestras feautures:\n",
    "\n",
    "- $X^{[T]}, Y^{[T]}$ dónde T es el tamaño el cual irémos dividiendo nuestros ejemplos.\n",
    "\n",
    "Esto del mini batch es llamado un epoch, que no es más que ir leyendo cada mini batch para que podamos realizar un mejor entrenamiento:\n",
    "\n",
    "<img src = 'HT_2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo escogemos nuestro mini-batch size?:\n",
    "\n",
    "Entonces, en este caso, lo que hacemos es que:\n",
    "\n",
    "- Si, nuestro minibatch size es igual a m, entonces estamos usando batch gradient descent\n",
    "\n",
    "- Si, nuestro minibatch size es igual a 1, entonces estamos usando stochastic gradient descent, que no es más que tomar cada uno de nuestros ejemplos, hasta m. \n",
    "\n",
    "¿Qué sería lo mejor?\n",
    "\n",
    "- Tomar un número entre 1 y m, normalmente, potencia de 2, es decir, $2^6, 2^4$ entre otros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponentially Weighted Averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, lo que queremos es usar un modelo autoregresivo con medias móviles, para ajustar los datos a medias móviles.\n",
    "\n",
    "En ese caso, nuestra ecuación sería:\n",
    "\n",
    "- $V_t = \\beta V_{t-1} + (1-\\beta)\\theta_t$\n",
    "\n",
    "Para cada mini batch t, lo que hacemos es ir ajustando nuestro beta para ir ajustando la curva.\n",
    "\n",
    "Ahora, este cálculo nos puede ayudar a realizar un descenso del gradiente con momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descenso del gradiente con momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso particular, lo que hacemos es en vez de calcularlo como siempre, se reemplaza el dw por el cálculo de V para ese dw en cada peso.\n",
    "\n",
    "<img src = HT_3.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtendríamos dos hiperparámetros esta vez, que serían alpha y beta.\n",
    "\n",
    "Ahora bien, con el momentum es una forma de hacer que nuestro algoritmo sea más "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema de hacer tuneo de hiperparámetros es que tenemos demasiados dependiendo de nuestro caso:\n",
    "\n",
    "- $\\alpha$: Learning Rate\n",
    "- $\\beta$: Momentum\n",
    "- $\\beta_{1}, \\beta_{2}, \\epsilon$: Hiperparámetros para adam\n",
    "- número de capas\n",
    "- número de neuronas\n",
    "- learning rate decay\n",
    "- mini-batch size.\n",
    "\n",
    "En este caso, el más importante es el learning rate. En los otros casos, los segundos importantes son el momentum, el número de neuronas y el mini-batch size.\n",
    "\n",
    "### PROTIP: Nunca usar un grid, intenta valores randoms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Deep_Learning': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3588fb9ea7dff2eb2287700cb5e34b8525e27f87c085349e2456f200952a0a0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
