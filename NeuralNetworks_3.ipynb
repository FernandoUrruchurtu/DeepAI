{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales Convolucionales "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer Vision and Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un problema importante con el computer vision es que para redes neuronales clásicas, con imágenes de alta resolución, es importante saber que cada vez el problema se vuelve poco factible sin prevenir el overfitting. Para ello, es importante saber que la operación de la convolución es mucho más eficiente.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que hace el computer vision con las redes neuronales, es tal vez detectar bordes o edges. Este lo que hace es tomar un **kernel** o un **filter** (como se llamará en el resto de videos) y hacer la operación de convolución, que se va a denotar con un asterisco (*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que se hace, es que este filter o kernel se toma una parte de la matriz general con el mismo tamaño y se hace un movimiento hasta recorrer toda la matriz original. Y se van poniendo los valores en otra matriz. Así el algoritmo detecta patrones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En python se pueden usar estas funciones:\n",
    "- conv-forward\n",
    "- TF: tf.nn.conv2d\n",
    "- CARIS: Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tema de los filtros, influye en como se quiere detectar los bordes en una imagen, ejemplo:\n",
    "\n",
    "<img src = CN_1.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, uno puede tomar los filtros o kernels de algunos investigadores. Sin embargo, es posible que en vez de tomar algo a mano, es posible coger este filtro y ponerlo como pesos de nuestra red neuronal para que los aprenda a detectar usando back-prop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes que nada, es importante que tengamos la denotación de las fórmulas que se van a utilizar. Cuando hacemos la operación de la convolución en una matriz de $(n, n)$ con un kernel/filtro de $(f, f)$ la matriz resultante va a ser de tamaño: $(n-f+1, n-f+1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, el problema con sólo aplicar la convolución, es que dejamos por fuera los pixeles de las esquinas o de la mitad, a sabiendas de que existen varias matrices que pueden rodear estas imágenes. Además, que el tema es que comprime nuestra imagen cada vez más, volviendola pixelada.\n",
    "\n",
    "Este problema, se soluciona con el padding, en este caso, se va añadiendo una imagen cada vez más para cubrir estos bordes. Entonces:\n",
    "\n",
    "Sea $p$ el número de pads que haremos para cubrir la imagen, nuestra matriz final queda de tamaño: $(n+2p-f+1, n+2p-f+1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces,\n",
    "\n",
    "#### Cuanto debe ser el valor de p que podemos dar\n",
    "\n",
    "En este caso, tenemos dos metodologías: Valid and Same Convolutions\n",
    "\n",
    "En una valida, quiere decir que no hay padding. Caso contrario, en las sames, lo que se usa es un número tal que termine del mismo tamaño que la imagen de destino. En este caso:\n",
    "\n",
    "- $n+2p-f+1 = n$\n",
    "\n",
    "- Entonces: $p = \\frac{f-1}{2}$\n",
    "\n",
    "Siendo que, siempre f es un par."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strided Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, en vez de añadir un pixel más con el padding, lo que hacemos es añadir un stride, lo que significa realizar un paso adicional, al que se hace tradicionalmente, es ir rodando la el filtro de tal manera que entre cada paso, se salten s pixeles. Esto nos deja con el siguiente tamaño de matriz:\n",
    "\n",
    "- $(\\lfloor\\frac{n+2p-f}{s}\\rfloor, \\lfloor\\frac{n+2p-f}{s}\\rfloor)$\n",
    "\n",
    "Si esto no da un entero, se redondea hasta abajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convultions over volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, hemos aplicado y explicado esta fórmula sobre sólo una matriz de uno de los canales. En este caso, ya no usamos un sólo canal de color, ahora usamos el canal RGB. En este caso, si tenemos una matriz de 6x6x3 siendo el primer número la altura, el segundo el ancho y el tercero los canales. \n",
    "\n",
    "Nuestro filtro también debe ser un 3x3x3. Igual seguiremos obteniendo una matriz de 4x4 al aplicar la operación de convolución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, esto implica que:\n",
    "\n",
    "- La mayoría de veces, nuestro kernel/filter va a tener los mismos canales que nuestra imagen.\n",
    "\n",
    "Sin embargo, podemos tener un filtro que sólo se enfoque a uno sólo de los canales, a 2 o a los 3 canales RGB.\n",
    "\n",
    "Adicional:\n",
    "\n",
    "- Al realizar la convolución, siempre tendremos una matriz en dos dimensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra idea que podemos tener en cuenta, es que tal vez queremos detectar otros features en nuestra imagen, podemos aplicar dos filtros distintos, y ponerlas juntas para tener un volume en la convolución, es decir, tomamos las dos y la ponemos juntas, que dependiendo del número que usemos, tendremos un output con una tercera dimensión. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Layer of a Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos hacer una red convolucional, podemos hacer el simil con una de una sóla neurona convolucional:\n",
    "\n",
    "<img src = 'CN_2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El último valor o dimensión de la matriz, siempre depende de todos los filtros que apliquemos. Entonces:\n",
    "\n",
    "- Si tenemos 10 filtros, que son todos 3x3x3, ¿Cuantos parámetros debemos aprender?. En este caso, serían 27 parámetros por cada filtro, y sumando el bias, tendriamos 28. En total terminaríamos con **280 parámetros**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notación para una red convolucional:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $f^{[l]}$ = tamaño del filtro para una capa $l$\n",
    "\n",
    "- $p^{[l]}$ = es el padding\n",
    "\n",
    "- $s^{[l]}$ = este sería el stride\n",
    "\n",
    "- $n^{[l]}_{c}$ = Número de filtros\n",
    "\n",
    "- Input: $(n^{[l-1]}_{H}, n^{[l-1]}_{W}, n^{[l-1]}_{c})$\n",
    "\n",
    "- Output: $(n^{[l]}_{H}, n^{[l]}_{W}, n^{[l]}_{c})$\n",
    "\n",
    "- $(n^{[l]}_{H,W} = \\lfloor\\frac{n^{[l]}_{H, W}+2p^{[l]}-f^{[l]}}{s^{[l]}} + 1\\rfloor)$\n",
    "\n",
    "Ahora bien, cada filtro será de tamaño:\n",
    "\n",
    "- $(f^{[l]}, f^{[l]}, n^{[l-1]})$\n",
    "\n",
    "Y nuestra activación:\n",
    "\n",
    "- $a^{[l]} = (n^{[l]}_{H}, n^{[l]}_{W}, n^{[l]}_{c})$\n",
    "\n",
    "- $A^{[l]} = (m, n^{[l]}_{H}, n^{[l]}_{W}, n^{[l]}_{c})$\n",
    "\n",
    "- $w^{[l]} = (f^{[l]}, f^{[l]}, n^{[l-1]}, n^{[l]})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En una red neuronal convolucional típica, tenemos varias capas:\n",
    "\n",
    "- La que realiza la convolución: Convolution\n",
    "\n",
    "- Otra es la Pooling Layer\n",
    "\n",
    "- La otra es Fully Connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las pooling layer básicamente lo que hacen es reducir la imagen de hasta comprimirla.\n",
    "\n",
    "- Hay un tipo de pooling llamada max pooling, esta simplemente toma el valor máximo de cada región en el filtro de pooling. Dividiendo nuestra matriz, por ejemplo, de 4x4 en 4 regiones diferentes y marcadas.\n",
    "\n",
    "Una ventaja, es que si bien, tiene dos hiperparámetros que serían el número de filtros y el stride que son los pasos a dar en cada región, no tiene parámetros para aprender.\n",
    "\n",
    "- Hay otro tipo que sería el average pooling, este simplemente toma el promedio de pixeles en cada una de las regiones del filtro.\n",
    "\n",
    "- Normalmente, no se usa padding en pooling, salvo en un caso particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea de las convoluciones, es tratar de que se detecten patrones basados precisamente en los valores de las imágenes.\n",
    "\n",
    "Una ventaja es que comparten parámetros, es decir, al detectar una característica, lo que hace es precisamente usarlo en otra parte de la imágen para detectar el mismo patrón."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LeNet-5\n",
    "- AlexNet\n",
    "- Vgg\n",
    "- ResNet\n",
    "- Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta red neuronal, usa pooling layers (Con Averages), y al final una red densa conectada completamente con 120 neuronas, luego otra con 84 y al final una predicción de $\\hat{y}$. Esta predicción puede darse usando una función de softmax. \n",
    "\n",
    "Si observamos, el $n_H$ y el $n_W$ tienden a ir hacia abajo a través de la red, mientras que el número de canales tiende a crecer. En este caso, podemos tener Conv-Pool-Conv-Pool-FC-FC-Output.\n",
    "\n",
    "Otro tema, es que se solian usar Tanh o funciones sigmoides para la activación. Adicional, la original, tenía activaciones no lineales luego de aplicar el pooling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, Alex Net usa max pooling, ene ste caso, también aumentan los números de canales y disminuyen el tamaño de la imagen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Están construidas con un bloque residual. Van con una activación linear, RelU, Linear y luego RElu. Ahora, en vez de ir directamente por el camino principal, ahora puede tomar un atajo para ir más profundo en la red neuronal.\n",
    "\n",
    "Se aplica una Non-Linearity Function.\n",
    "\n",
    "Usar bloques residuales es mejor para entrenar redes neuronales más profundas. Al usar una red neuronal plana, en la realidad, es que nuestro algoritmo de optimización le tomará más tiempo encontrar un óptimo, por lo que puede desmejorar a medida que hacemos nuestra red neuronal más profunda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es más facil para un bloque residual aprender una función de identidad. Esto es por que si son negativas, simplemente se hace cero toda la expresión de los ceros. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de los beneficios de usar pooling layers o conv layers, el costo computacional de estimar todos estos parámetros, se reduce 1/10 parte si se aplica un filtro de una convolución de 1x1 teniendo como base de que se realizarán las mismas operaciones sin dañar el performance de la red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay dos terminologías importantes. La primera es saber que en el caso de detectar objetos, hay un sólo objeto. Pero cuando queremos hacer detección, es diferente por que tenemos varios objetos. \n",
    "\n",
    "En este caso, se tiene una función de softmax cómo salida de la red neuronal para detectar objetos en un cuadro. Si quieres localizar el carro, debes tener varias unidades que saldrán 4 nuevos outputs:\n",
    "\n",
    "- $b_x, b_y, b_h, b_w $ -> Estos serían bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero, es preguntarnos si ¿hay un objeto? dónde esta clase puede ser cualquiera de las definidas por la persona que hará el modelo.\n",
    "\n",
    "La nomenclatura es $P_{c}$ este va a ser la probabilidad de que haya un objeto. Los bounding boxes será otro componente del output. Adicional, habrán una de las clases que se hayan definido por el usuario.\n",
    "\n",
    "En el caso de que no haya un objeto, no importa, por que en realidad no hay ninguno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo principal es destacar o dejar claro que existen dos problemas:\n",
    "\n",
    "- Problema de verificación, en este caso ingreso una imagen de una persona, o su ID y verifico que esta sea la persona. En este caso, el problema es uno a uno.\n",
    "\n",
    "- Problema de reconocimiento de caras, para este apartado, tenemos una base de datos con K personas, le ingresamos una imagen y se reconoce si esta es una de esas tantas personas.\n",
    "\n",
    "Pasar de uno al otro, se convierte en un problema de \"One-Shot Learning\" en el que tenemos que usar sólo un ejemplo de una persona para que el algoritmo verifique si esta es la persona o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea en este caso, es que el algoritmo sea capaz de aprender una función de \"similaridad\". Es decir, que sea capaz de comparar una persona con la otra.\n",
    "\n",
    "En este sentido, la función que va a aprender el algoritmo, corresponde a: $d(img1, img2)$ que no es más que el grado de diferencia entre imágenes. Para esta función, definimos un límite el cual es un nuevo hiperparámetro, el cual va a indicar la tolerancia a la cual vamos a admitir que existe un grado de diferencia entre las imágenes.\n",
    "\n",
    "Para lograr el face recognition, usamos una red siamés, es decir, dos redes gemelas, que tendrán los mismos parámetros, pero realizarán un encoding diferente para cada una de las imágenes. Una vez cada una dé sus resultados luego de realizar el \"encoding\", se cálcula una distancia euclidiana, que sería la norma de ambas funciones elevado al cuadrado.\n",
    "\n",
    "Más formalmente:\n",
    "\n",
    "- Los parámetros de una red neuronal definen el encoding $f(x^{(i)})$ dada una imágen $x^{(i)}$\n",
    "\n",
    "- Al final, queremos aprender los parámetros tales que dos imágenes $x^{(i)}$ y $x^{(j)}$ son la misma persona, dado que $||f(x^{(i)})-f(x^{(j)})||^{2}$ es pequeño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplet Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una forma de que nuestra red neuronal aprenda los parámetros necesarios para que estas condiciones se cumplan, es usando una función de pérdida llamada Triplet.\n",
    "\n",
    "En este caso, necesitamos comparar dos pares de imágenes, una que sería el Anchor que sería la persona con la que se está comparando. Otro sería efectivamente la misma persona, positiva y una persona que sería la negativa, es decir, el input, output correcto, output incorrecto. Es por eso que es llamada Triplet Loss Function.\n",
    "\n",
    "- Tenemos lo siguiente: A: Anchor, P: positive, N: Negative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, esto garantiza que en promedio, nuestra red neuronal aprenda a poner todas las normas en cero. En este caso, la fórmula final final no va más, sería la siguiente:\n",
    "\n",
    "- $||f(A)-f(P)||^{2}-||f(A)-f(N)||^{2} + \\alpha \\leq 0$\n",
    "\n",
    "Dónde $\\alpha$ no es más que otro hiperparámetro que nos va a permitir tener un nivel de tolerancia para que nuestra red neuronal no siempre de cero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de Triplet sería definida de la siguiente manera:\n",
    "\n",
    "- Dada tres imágenes: A, P y N, $L(A,P,N) = max(||f(A)-f(P)||^{2}-||f(A)-f(N)||^{2} + \\alpha , 0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Recognition resuelto cómo una clasificación binaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso anterior, usamos esta función, en la cual, es necesario que tengamos un Anchor, una foto Positive o una negativa y que además, es necesario que la red neuronal sea difícil de entrenar, tal que se escojan los P y los N que sean lo más cercanos entre si. Así, tiene validez el márgen que seleccionamos como hiperparámetro.\n",
    "\n",
    "Si lo hacemos como una clasificación binaria, podemos decir que:\n",
    "\n",
    "- $\\hat{y} = \\sigma{(\\sum_{k=1}^{128}w_{k}|f(x^{(i)})_{k}-f(x^{(j)})_{k}|+b)}$ siendo 128 el tamaño que podría tener el encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Style Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que se busca, es que dada una imágen real, llamada C, una con un estilo particular, llamada S, genera una imágen G con ciertos filtros y mismo estilo que la imagen anterior. Para lograr esto, debemos saber que cosas está aprendiendo nuestra red neuronal a través de cada una de las imágenes tal que podamos tener estas características y aplicarlas a la otra imágen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Deep_Learning': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3588fb9ea7dff2eb2287700cb5e34b8525e27f87c085349e2456f200952a0a0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
