{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de Secuencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos de secuencias han impactado en:\n",
    "\n",
    "- Reconocimiento de voz\n",
    "- Generación de música\n",
    "- Clasificación de Sentimientos\n",
    "- Secuencias de ADN\n",
    "- Machine Translation\n",
    "- Reconocimiento de actividades en video\n",
    "- Reconocimiento de nombres de entidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para representar las posiciones de nuestro X input, usamos la siguiente notación:\n",
    "\n",
    "- $X^{<1>}$: Para el primer ejemplo. En este caso, en un modelo de secuencias, buscamos que cada uno esté en un espacio -temporal- por ello, denotamos cualquier posición con la letra $t$ -> $X^{<T>}$\n",
    "\n",
    "Para el caso particular de las secuencias de palabras, es posibles utilizar en el caso de NLP un One-Hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Por qué no usar una red neuronal estándar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que pasa si hacemos un feeding de cada vector en One Hot encoding a una red neuronal estándar?\n",
    "\n",
    "En este caso tendríamos un problema y es que cada input y cada output puede ser de diferentes tamaños. Adicional, no comparte características aprendidas en cada diferente posición de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, ¿Qué hace una red neuronal recurrente?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una red neuronal recurrente, lo que hace es que lee cada vector en -One Hot Encoding- en cada paso y adicional, toma como referencia el valor de la activación en el paso anterior. \n",
    "\n",
    "Es decir, si le ingreso $X^{<1>} \\to \\hat{y}^{<1>}$ y luego, usa este resultado, en paso siguiente $[X^{<1>} \\to \\hat{y}^{<1>}] \\to [X^{<2>} \\to \\hat{y}^{<2>}]$ y así en cada uno hasta llegar al Tth ejemplo. \n",
    "\n",
    "Usando como activación inicial, lo más común, un vector de ceros. Escanea todo los datos desde la izquierda hasta la derecha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una debilidad de esto, es que utiliza para hacer su predicción, los time_steps que estén más tempranos o cercanos al valor a predecir, esta es una desventaja ya que no utiliza nada del futuro cercano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una versión de cómo puede verse la red neuronal es de esta forma:\n",
    "\n",
    "<img src = 'NN_12.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, nótese que los pesos de cada paso en la red neuronal, van a ser los mismos durante toda la recurrencia, esto es ya que conserva información del pasado sin tener en cuenta el futuro cercano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, en cada iteración, tendríamos las siguientes fórmulas en una red recurrente:\n",
    "\n",
    "- $a^{<t>} = g(W_{aa}a^{<t-1>}+(W_{ax}x^{<t>}+b_a)$\n",
    "\n",
    "- $\\hat{y}^{<t>} = g(W_{ya}a^{<t>}+b_y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay un tipo en el que queremos, por ejemplo, tener un resultado particular en nuestra red neuronal. Ejemplo de esto, es que queremos generar una clasificación basada en varios inputs, en este caso, estaríamos hablando de una relación Many-To-One o muchos a uno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos tener un One-To-Many, este siendo uno que relaciona uno a muchos. Un ejemplo es en generación de música a partir de una nota en particular. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay un ejemplo particular en el que tenemos un Many-To-Many o muchos a muchos, entonces en estos casos, la entrada y la salida pueden tener diferentes tamaños en cuánto a vectores, entonces, en ejemplos anteriores vemos que todos deben tener al menos el mismo tamaño.\n",
    "\n",
    "Una forma de solucionarlo, es que tenemos en una primera parte el Encoder, el cual primero a va leer todo el input y luego el Decoder, que sólo va a generar la salida con un tamaño diferente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'NN_13.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que hace la red neuronal al modelar lenguajes, es simplemente cálcular la probabilidad de ser una sentencia u otra, tomando la que mejor probabilidad tenga de ser lo que escribimos o decimos. \n",
    "\n",
    "Para el modelamiento, necesitamos que nuestro Training set tenga un gran cuerpo de texto, ya sea en inglés o español.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que se hace, es tokenizar las palabras, cómo vimos en la lectura pasada, lo que busca es hacer One-Hot Encoding en nuestro corpus de tal manera que genera un vector con cada palabra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qué realiza nuestra red recurrente en este caso? En general, empieza a calcular las probabilidades de tener una palabra detrás de otra, dándo a cada paso adelante, la posibilidad de aprender con la sentencia, cual sería la palabra más probable para seguir hasta terminar con la oración. Es decir, cálcula probabilidades condicionales, dado el pasado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, como al final estamos tratando con probabilidades, lo que buscamos es que nuestra función de costo sea una logística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, una vez modelado el lenguaje y entrenado, para hacer el sampling, lo que hacemos es que se toma una palabra teniendo en cuenta la distribución de probabilidades. En el siguiente paso, se toma como salida, la palabra con mayor probabilidad, pasándose por cada uno de los pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, ¿cómo sabemos cuando acabará el sampling?. En este caso simplemente podemos generar un token de EOS. Adicional, es posible que la red genere tokens de UNK. Lo mejor para esta situación es indicar que se rechace siempre un UNK y luego se mantenga haciendo resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, hasta ahora hemos estado viendo cómo sería un modelado a nivel de palabras, pero también podemos hacerlo a nivel de caracteres, se añaden estos a un vocabulario ya tokenizado, pero sería muy costoso de entrenar y las oraciones serían mucho más largas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanishing gradients Problem With RNN's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las RNN es posible que nos encontremos que, sentencias muy largas cuyos pequeños cambios se presentan temprano en la secuencia, pueden afectar al resultado final de la secuencia, ejemplo de esto, es cuando armamos una oración que empieza en plural o singular, es decir, si decimos The cats.... were full o The cat.... was full, siendo los puntos entre cada oración largas cadenas de texto. \n",
    "\n",
    "Toma bastante tiempo volver atrás en la secuencia de RNN lo que ocasiona el problema del título.\n",
    "\n",
    "Debido a esto, muchos modelos tienen influencias locales, quiere decir que cada una de las salidas u outputs, se ve influenciado por sus más cercanos.\n",
    "\n",
    "Esto va a ocasionar Exploding Gradients también como Vanishing, ya que el error se va a propagar más lento y no va a poder realizar los cálculos necesarios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU o Gated Recurrent Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una célda GRU es una celda que guarda en memoria o \"recuerda\" por así decirlo, si, en el ejemplo de los gatos, si la oración es en plural o singular"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Deep_Learning': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3588fb9ea7dff2eb2287700cb5e34b8525e27f87c085349e2456f200952a0a0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
